{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Agent Plan Simple Example\n",
        "\n",
        "This python notebook shows how to use the unified planning library to model multi-agent problems.",
        "\n",
        "[![Open In GitHub](https://img.shields.io/badge/see-Github-579aca?logo=github)](https:///github.com/aiplan4eu/unified-planning/blob/master/docs/notebooks/09-multiagent-planning-simple.ipynb)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aiplan4eu/unified-planning/blob/master/docs/notebooks/09-multiagent-planning-simple.ipynb)"
      ],
      "metadata": {
        "id": "QiGealjaVJNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "We start by downloading (from github) the unified planning library and a multi-agent planner (FMAP)."
      ],
      "metadata": {
        "id": "JvKlg7cm8tBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIxg95xz5EMo",
        "tags": [
          "remove_from_CI"
        ],
        "outputId": "44a3c006-f512-4f4e-9051-fab23c83970d"
      },
      "outputs": [],
      "source": [
        "!pip install --pre unified-planning[fmap]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to use the Unified-Planning library!"
      ],
      "metadata": {
        "id": "OY-4EFALUj00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo\n"
      ],
      "metadata": {
        "id": "Vh5X0ZqRVVEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo we show how to model a multi-agent planning problem using the Unified Planning library."
      ],
      "metadata": {
        "id": "LY7O_siBU0V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic imports"
      ],
      "metadata": {
        "id": "tiQrjJOsV5zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unified_planning.shortcuts import *\n",
        "from unified_planning.model.multi_agent import *\n",
        "from collections import namedtuple\n",
        "from unified_planning.io.ma_pddl_writer import MAPDDLWriter"
      ],
      "metadata": {
        "id": "dF8NSQydRRBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating the simple-MA problem"
      ],
      "metadata": {
        "id": "lUvelsbfWE9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class that represents a multi-agent planning problem is unified_planning.MultiAgentProblem, it contains the set of agents, the objects, an intial value for all the fluents and a goal to be reached by the planner.\n",
        "We create a `MultiAgentProblem` and two `Agents`. An `Agent` is an individual entity with specific fluents and specific\n",
        "actions."
      ],
      "metadata": {
        "id": "WK2NwCw7XPB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem = MultiAgentProblem(\"simple_MA\")\n",
        "\n",
        "#AGENTs\n",
        "robot_a = Agent(\"robot_a\", problem)\n",
        "scale_a = Agent(\"scale_a\", problem)"
      ],
      "metadata": {
        "id": "xtPm63jkRRIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the UserTypes, the Objects, the Fluents and the Actions"
      ],
      "metadata": {
        "id": "_4P9_BnPeXA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#USERTYPEs\n",
        "Location = UserType(\"Location\")\n",
        "door = UserType(\"door\")\n",
        "\n",
        "#FLUENTs\n",
        "open = Fluent(\"open\", door=door)\n",
        "pos = Fluent(\"pos\", loc=Location)\n",
        "\n",
        "#OBJECTs\n",
        "home = Object(\"home\", Location)\n",
        "office = Object(\"office\", Location)\n",
        "open20 = Object(\"open20\", door)\n",
        "close20 = Object(\"close20\", door)\n",
        "\n",
        "#ACTIONs\n",
        "movegripper = InstantaneousAction(\"movegripper\")\n",
        "movegripper.add_precondition(pos(office))\n",
        "movegripper.add_effect(pos(home), True)\n",
        "\n",
        "open_door = InstantaneousAction(\"open_door\")\n",
        "open_door.add_precondition(open(close20))\n",
        "open_door.add_effect(open(open20), True)"
      ],
      "metadata": {
        "id": "66JwC79NRRMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add the `Fluents` to the `Agents`. Note: An agent's fluent can be of two types, public or private. `Public Fluents` are visible to other agents. In contrast, the `Private Fluents` are not visible from the other agents.\n",
        "Private fluents are added to the agent via the `add_fluent` or `add_private_fluent` methods and public fluents via the `add_public_fluent` method."
      ],
      "metadata": {
        "id": "NIejvKXAetMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robot_a.add_fluent(pos, default_initial_value=False)\n",
        "scale_a.add_fluent(open, default_initial_value=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhlkeJ-ge2of",
        "outputId": "21cceb3b-a180-49cf-dff0-3a5a1e339a96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We add to the agents the actions they can perform."
      ],
      "metadata": {
        "id": "4uhPijdDivoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robot_a.add_action(movegripper)\n",
        "scale_a.add_action(open_door)"
      ],
      "metadata": {
        "id": "4pCaQ6cQRRQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add the agents to the `MultiAgentProblem`."
      ],
      "metadata": {
        "id": "WOFJtvHnjC_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem.add_agent(robot_a)\n",
        "problem.add_agent(scale_a)"
      ],
      "metadata": {
        "id": "ZK0kyCHUjCVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We add the objects, the initial values and the goals. \n",
        "Note: `Dot` operator is used to denote agent-specific `Fluents`."
      ],
      "metadata": {
        "id": "Pl78ABIni9FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OBJECTs\n",
        "problem.add_object(home)\n",
        "problem.add_object(office)\n",
        "problem.add_object(open20)\n",
        "problem.add_object(close20)\n",
        "\n",
        "#INITIAL VALUEs\n",
        "problem.set_initial_value(Dot(robot_a, pos(office)), True)\n",
        "problem.set_initial_value(Dot(scale_a, open(close20)), True)\n",
        "\n",
        "#GOALs\n",
        "problem.add_goal(Dot(robot_a, pos(home)))\n",
        "problem.add_goal(Dot(scale_a, open(open20)))"
      ],
      "metadata": {
        "id": "tXu5TET8RRWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MA-PDDL Writer"
      ],
      "metadata": {
        "id": "-mJ_Lrl6nTcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To write the ma-pddl equivalent of a `unified_planning MultiAgentProblem` to a file we use the `MAPDDLWriter.write_ma_domain` and `MAPDDLWriter.write_ma_problem` methods."
      ],
      "metadata": {
        "id": "KEkzMePBpB3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = MAPDDLWriter(problem)\n",
        "w.write_ma_domain(\"simple_ma\")\n",
        "w.write_ma_problem(\"simple_ma\")"
      ],
      "metadata": {
        "id": "zI9eG8iWRvUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solving Multi-Agent Planning Problems"
      ],
      "metadata": {
        "id": "UxrMTuOqVmzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The user can enter the following optional parameters in order to configure the search procedure:\n",
        "\n",
        "`result = planner.solve(problem, \"-s\", \"h\")`:\n",
        "\n",
        "- s N selects the search strategy of FMAP. Currently, FMAP supports only an A search scheme, which is the default value of the tag -s (-s None)"
      ],
      "metadata": {
        "id": "WeCeV3WrXYNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- h N selects the heuristic function(s) used to evaluate the quality of the plans. Currently, the following values for N are supported:\n",
        "\n",
        "  - 0 - FF heuristic: guides the search through the well-known h_FF heuristic function. This option is available for single-agent planning tasks only.\n",
        "  - 1 - DTG heuristic: evaluates plans via the heuristic h_DTG.\n",
        "  - 2 - default option - DTG + Landmarks: this option applies the multi-heuristic search scheme of the MH-FMAP solver by combining the h_DTG and h_Land heuristics to guide the search.\n",
        "  - 3 - Inc. DTG + Landmarks: incremental multi-heuristic mode that makes use of h_DTG and h_Land."
      ],
      "metadata": {
        "id": "9SRCqarrVo6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with OneshotPlanner(name='fmap') as planner:\n",
        "    result = planner.solve(problem, None, \"1\")\n",
        "    if result.status == up.engines.PlanGenerationResultStatus.SOLVED_SATISFICING:\n",
        "        print(\"%s Returned Sequential Plans object: %s\" % (planner.name, result.plan.all_sequential_plans()))\n",
        "        [print(f\"{idx} Sequential Plans: {seq_plan}\") for idx, seq_plan in enumerate(result.plan.all_sequential_plans())]\n",
        "        print(\"Adjacency list:\", result.plan.get_adjacency_list)\n",
        "        print(\"result:\", result)\n",
        "    else:\n",
        "        print(\"Log Error:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OF98T8i5ZOl",
        "outputId": "e812e0be-6c56-4903-f2ab-e4ddf331f289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\u001b[1mNOTE: To disable printing of planning engine credits, add this line to your code: `up.shortcuts.get_environment().credits_stream = None`\n",
            "\u001b[0m\u001b[96m  *** Credits ***\n",
            "\u001b[0m\u001b[96m  * In operation mode `OneshotPlanner` at line 1 of `<ipython-input-10-ef9b04792df7>`, \u001b[0m\u001b[96myou are using the following planning engine:\n",
            "\u001b[0m\u001b[96m  * Engine name: FMAP\n",
            "  * Developers:  Alejandro Torre√±o, Oscar Sapena and Eva Onaindia\n",
            "\u001b[0m\u001b[96m  * Description: \u001b[0m\u001b[96mFMAP: A Platform for the Development of Distributed Multi-Agent Planning Systems.\u001b[0m\u001b[96m\n",
            "\u001b[0m\u001b[96m\n",
            "\u001b[0mFMAP Returned Sequential Plans object: <generator object PartialOrderPlan.all_sequential_plans at 0x7fadf0c8cc10>\n",
            "0 Sequential Plans: [scale_a.open_door, robot_a.movegripper]\n",
            "1 Sequential Plans: [robot_a.movegripper, scale_a.open_door]\n",
            "Adjacency list: {robot_a.movegripper: [], scale_a.open_door: []}\n",
            "result: PlanGenerationResult(status=<PlanGenerationResultStatus.SOLVED_SATISFICING: 1>, plan=DiGraph with 2 nodes and 0 edges, engine_name='FMAP', metrics=None, log_messages=[LogMessage(level=<LogLevel.INFO: 2>, message='; Hdtg = 0, Hlan = 0\\n; Hdtg = 0, Hlan = 0\\n; Hdtg = 0, Hlan = 0\\n; Hdtg = 0, Hlan = 0\\n\\n; Solution plan - CoDMAP Distributed format\\n; -----------------------------------------\\n0: (movegripper robot_a)\\n0: (open_door scale_a)\\n; Stopping...\\n'), LogMessage(level=<LogLevel.ERROR: 4>, message='')])\n"
          ]
        }
      ]
    }
  ]
}